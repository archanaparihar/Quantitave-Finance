{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Cointegration for 2 clusters - found by K-Medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pit\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 20,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('C:/Users/archana.parihar/Downloads/ClustersFromR_2_K-Medoids.csv')\n",
    "dfCluster1m = df.loc[df['Cluster'] == 1]\n",
    "dfCluster2m = df.loc[df['Cluster'] == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "badCompanies = ['BMY', 'DHR', 'ES', 'ICE', 'ORCL', 'O', 'IQV', 'COTY', 'FOXA', 'FOX', 'NWSA', 'NWS', 'ALLE', 'GOOG', 'NAVI', 'INFO', 'SYF', 'CFG', 'QRVO', 'WRK', 'KHC', 'PYPL', 'HPE', 'HPQ', 'CSRA', 'WLTW', 'UA', 'FTV', 'EVHC', 'HLT', 'DXC', 'BHGE', 'BHF', 'DWDP', 'APTV', 'CBG', 'CHK', 'HCN', 'LUK', 'PCLN', 'PDCO', 'SIG', 'SNI', 'WYN', 'CSRA', 'ABMD', 'BKNG', 'CBRE', 'IPGP', 'JEF', 'MSCI', 'NKTR', 'SIVB', 'TTWO', 'WELL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1 = pd.read_csv('C:/Users/archana.parihar/Downloads/allStocks13-14-15.csv', parse_dates=True,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CointegrationOfCombinedSeries(timeSeries):\n",
    "    coint = False    \n",
    "    #plot rolling statistics to visualize whether it is stationary or not\n",
    "    ma = timeSeries.rolling(window=100).mean()\n",
    "    mstd = timeSeries.rolling(window=100).std()\n",
    "    \n",
    "   # timeSeries.plot()\n",
    "   # ma.plot(color='blue')\n",
    "   # mstd.plot(color='black')\n",
    "    \n",
    "    #perform dickey fuller to check quantitatively\n",
    "    dftest = adfuller(timeSeries,autolag= 'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#lags used','No of observations used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical value (%s)'%key]= value\n",
    "\n",
    "    #print(dfoutput) \n",
    "    #if dfoutput['Critical value (10%)']<-2.57  :\n",
    "       # print('The pair is most likely Cointegrated')\n",
    "        #coint = True\n",
    "    #if dfoutput['Critical value (10%)']>-2.57  :\n",
    "        #print('The pair is most likely NOT Cointegrated')\n",
    "    if dfoutput['p-value']<=0.02:\n",
    "        coint= True\n",
    "    return coint\n",
    "\n",
    "def ImproveStationarity_and_test_Cointegration(dfX,dfY):\n",
    "    #Convert closePrice of Time series X to log-Moving average time series for better value of regression coefficient\n",
    "    dfX_logScale = np.log(dfX['close'])\n",
    "    Xma = dfX_logScale.rolling(window=100).mean()\n",
    "    logScaleMinusMovingAverage1 = dfX_logScale - Xma\n",
    "    logScaleMinusMovingAverage1.dropna(inplace=True)\n",
    "\n",
    "    #Convert closePrice of Time series Y to log-Moving average time series for better value of regression coefficient\n",
    "    dfY_logScale = np.log(dfY['close'])\n",
    "    Yma = dfY_logScale.rolling(window=100).mean()\n",
    "    logScaleMinusMovingAverage2 = dfY_logScale - Yma\n",
    "    logScaleMinusMovingAverage2.dropna(inplace=True)\n",
    "\n",
    "    #Using linear regression to calculate the value of b for linearly combines Time series\n",
    "    logScaleMinusMovingAverage1 = sm.add_constant(logScaleMinusMovingAverage1)\n",
    "    results = sm.OLS(logScaleMinusMovingAverage2,logScaleMinusMovingAverage1['close']).fit()\n",
    "    b = results.params['close']\n",
    "    z = logScaleMinusMovingAverage1['close'] - (b * logScaleMinusMovingAverage2)\n",
    "    coint = test_CointegrationOfCombinedSeries(z)\n",
    "    return coint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster number: 0\n",
      "Old length of cluster : 117\n",
      "New length of cluster : 107\n",
      "Total pairs:  5671\n",
      "Number of True: 1485\n",
      "Number of False: 4186\n",
      "---------------------------------------------------------------\n",
      "Cluster number: 1\n",
      "Old length of cluster : 388\n",
      "New length of cluster : 354\n",
      "Total pairs:  62481\n",
      "Number of True: 11995\n",
      "Number of False: 50486\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def coIntTestForCluster(dfCluster,ClusterNumber):\n",
    "    print('Cluster number: '+ str(ClusterNumber))\n",
    "    ListOfCompInOneCluster = dfCluster['Name'].tolist()\n",
    "    print('Old length of cluster : '+ str(len(ListOfCompInOneCluster)))\n",
    "    for i in range(0,len(badCompanies)):\n",
    "        if badCompanies[i] in ListOfCompInOneCluster :\n",
    "            #print(\"Bad Company found in Cluster: \" , badCompanies[i])\n",
    "            ListOfCompInOneCluster.remove(badCompanies[i])\n",
    "    print('New length of cluster : '+ str(len(ListOfCompInOneCluster)))\n",
    "\n",
    "    ListOfPairs = list(itertools.combinations(ListOfCompInOneCluster, 2))\n",
    "    #print(ListOfPairs[:2])\n",
    "    #print(len(ListOfPairs))\n",
    "    #print(ListOfPairs[0][0],ListOfPairs[0][1])\n",
    "\n",
    "    pair_result_dict = {}\n",
    "    for x in range(0,len(ListOfPairs)):\n",
    "        pair_result_dict[ListOfPairs[x]] = []\n",
    "\n",
    "    for i in range(0,len(ListOfPairs)):\n",
    "        dfX = df1.loc[df1['Name']==ListOfPairs[i][0]]\n",
    "        dfY = df1.loc[df1['Name']==ListOfPairs[i][1]]\n",
    "        Result = ImproveStationarity_and_test_Cointegration(dfX,dfY)\n",
    "        pair_result_dict[ListOfPairs[i]] = Result\n",
    "\n",
    "    ListOfValuesCluster_2=list(pair_result_dict.values())\n",
    "    print('Total pairs:  ' + str(len(ListOfValuesCluster_2)))\n",
    "    print('Number of True: ' + str(ListOfValuesCluster_2.count(True)))\n",
    "    print('Number of False: ' + str(ListOfValuesCluster_2.count(False)))\n",
    "    print('---------------------------------------------------------------')\n",
    "    return pair_result_dict\n",
    "\n",
    "listOfClusters = [dfCluster1m,dfCluster2m]\n",
    "listOfResultDict = []\n",
    "\n",
    "for c in range(0,len(listOfClusters)):\n",
    "    res = coIntTestForCluster(listOfClusters[c],c)\n",
    "    listOfResultDict.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n"
     ]
    }
   ],
   "source": [
    "ListOfCointPairs = []\n",
    "for key, value in listOfResultDict[0].items():\n",
    "    if value == True:\n",
    "        ListOfCointPairs.append(key)\n",
    "        \n",
    "print(len(ListOfCointPairs))\n",
    "\n",
    "dfCoInt = pd.DataFrame({'Pairs':ListOfCointPairs})\n",
    "dfCoInt.head(5)\n",
    "dfCoInt.to_csv('C:/Users/archana.parihar/Downloads/ResultsSnP/ListOfPairs_2_Medoid_Cluster_1_pvalue_02.csv',index=False, sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11995\n"
     ]
    }
   ],
   "source": [
    "ListOfCointPairs = []\n",
    "\n",
    "for key, value in listOfResultDict[1].items():\n",
    "    if value == True:\n",
    "        ListOfCointPairs.append(key)\n",
    "        \n",
    "print(len(ListOfCointPairs))\n",
    "\n",
    "dfCoInt = pd.DataFrame({'Pairs':ListOfCointPairs})\n",
    "dfCoInt.head(5)\n",
    "dfCoInt.to_csv('C:/Users/archana.parihar/Downloads/ResultsSnP/ListOfPairs_2_Medoid_Cluster_2_pvalue_02.csv',index=False, sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
