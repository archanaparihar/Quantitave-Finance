{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archana.parihar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pit\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 20,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of Companies with clean data from allStock_5 year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies in All stock data for which we have stock data: 505\n"
     ]
    }
   ],
   "source": [
    "#List of company names in allStock data\n",
    "df2 = pd.DataFrame()\n",
    "df2 = pd.read_csv('C:/Users/archana.parihar/Downloads/ListOfCompanies.csv')\n",
    "dfList = df2['Company'].tolist()\n",
    "print('Number of companies in All stock data for which we have stock data: '+ str(len(dfList)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1 = pd.read_csv('C:/Users/archana.parihar/Downloads/allStocks13-14-15.csv', parse_dates=True,index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary with company name as index and count of observations as value\n",
    "data = {}\n",
    "for x in range(0,len(dfList)):\n",
    "    data[dfList[x]] = []\n",
    "for y in range(0,len(dfList)):\n",
    "    data[dfList[y]] = (df1.Name == dfList[y]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies with incomplete data : 35\n",
      "['BMY', 'DHR', 'ES', 'ICE', 'ORCL', 'O', 'IQV', 'COTY', 'FOXA', 'FOX', 'NWSA', 'NWS', 'ALLE', 'GOOG', 'NAVI', 'INFO', 'SYF', 'CFG', 'QRVO', 'WRK', 'KHC', 'PYPL', 'HPE', 'HPQ', 'CSRA', 'WLTW', 'UA', 'FTV', 'EVHC', 'HLT', 'DXC', 'BHGE', 'BHF', 'DWDP', 'APTV']\n"
     ]
    }
   ],
   "source": [
    "#Find list of companies with insufficient data\n",
    "count = 0\n",
    "badCompanies = []\n",
    "for i in data:\n",
    "    if(data[i]<730):\n",
    "        count = count+1\n",
    "        badCompanies.append(i)\n",
    "print('Companies with incomplete data : '+ str(count))\n",
    "print(badCompanies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies in R clusters for which we company related data: 505\n",
      "Companies with bad data : 55\n",
      "['BMY', 'DHR', 'ES', 'ICE', 'ORCL', 'O', 'IQV', 'COTY', 'FOXA', 'FOX', 'NWSA', 'NWS', 'ALLE', 'GOOG', 'NAVI', 'INFO', 'SYF', 'CFG', 'QRVO', 'WRK', 'KHC', 'PYPL', 'HPE', 'HPQ', 'CSRA', 'WLTW', 'UA', 'FTV', 'EVHC', 'HLT', 'DXC', 'BHGE', 'BHF', 'DWDP', 'APTV', 'CBG', 'CHK', 'HCN', 'LUK', 'PCLN', 'PDCO', 'SIG', 'SNI', 'WYN', 'CSRA', 'ABMD', 'BKNG', 'CBRE', 'IPGP', 'JEF', 'MSCI', 'NKTR', 'SIVB', 'TTWO', 'WELL']\n"
     ]
    }
   ],
   "source": [
    "#Add those companies to bad company list, that are present in the Cluster from R and not there in allStocks data\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('C:/Users/archana.parihar/Downloads/ClustersFromR.csv')\n",
    "ListOfCompFromClusters_R = df['Name'].tolist()\n",
    "for i in range(0,len(dfList)):\n",
    "    if dfList[i] not in ListOfCompFromClusters_R :\n",
    "        badCompanies.append(dfList[i])\n",
    "for i in range(0,len(ListOfCompFromClusters_R)):\n",
    "    if ListOfCompFromClusters_R[i] not in dfList :\n",
    "        badCompanies.append(ListOfCompFromClusters_R[i])\n",
    "print('Number of companies in R clusters for which we company related data: '+ str(len(ListOfCompFromClusters_R)))\n",
    "print('Companies with bad data : '+ str(len(badCompanies)))\n",
    "print(badCompanies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Cointegration for 5 clusters - found by K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('C:/Users/archana.parihar/Downloads/ClustersFromR_KMeans.csv')\n",
    "dfCluster1m = df.loc[df['Cluster'] == 1]\n",
    "dfCluster2m = df.loc[df['Cluster'] == 2]\n",
    "dfCluster3m = df.loc[df['Cluster'] == 3]\n",
    "dfCluster4m = df.loc[df['Cluster'] == 4]\n",
    "dfCluster5m = df.loc[df['Cluster'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CointegrationOfCombinedSeriesKMean(timeSeries):\n",
    "    coint = False    \n",
    "    #plot rolling statistics to visualize whether it is stationary or not\n",
    "    ma = timeSeries.rolling(window=100).mean()\n",
    "    mstd = timeSeries.rolling(window=100).std()\n",
    "    \n",
    "   # timeSeries.plot()\n",
    "   # ma.plot(color='blue')\n",
    "   # mstd.plot(color='black')\n",
    "    \n",
    "    #perform dickey fuller to check quantitatively\n",
    "    dftest = adfuller(timeSeries,autolag= 'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#lags used','No of observations used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical value (%s)'%key]= value\n",
    "\n",
    "    #print(dfoutput) \n",
    "    #if dfoutput['Critical value (10%)']<-2.57  :\n",
    "       # print('The pair is most likely Cointegrated')\n",
    "       # coint = True\n",
    "    #if dfoutput['Critical value (10%)']>-2.57  :\n",
    "        #print('The pair is most likely NOT Cointegrated')\n",
    "    if dfoutput['p-value']<=0.02:\n",
    "        coint= True\n",
    "        \n",
    "    return coint\n",
    "\n",
    "def ImproveStationarity_and_test_CointegrationKMean(dfX,dfY):\n",
    "    #Convert closePrice of Time series X to log-Moving average time series for better value of regression coefficient\n",
    "    dfX_logScale = np.log(dfX['close'])\n",
    "    Xma = dfX_logScale.rolling(window=100).mean()\n",
    "    logScaleMinusMovingAverage1 = dfX_logScale - Xma\n",
    "    logScaleMinusMovingAverage1.dropna(inplace=True)\n",
    "\n",
    "    #Convert closePrice of Time series Y to log-Moving average time series for better value of regression coefficient\n",
    "    dfY_logScale = np.log(dfY['close'])\n",
    "    Yma = dfY_logScale.rolling(window=100).mean()\n",
    "    logScaleMinusMovingAverage2 = dfY_logScale - Yma\n",
    "    logScaleMinusMovingAverage2.dropna(inplace=True)\n",
    "\n",
    "    #Using linear regression to calculate the value of b for linearly combines Time series\n",
    "    logScaleMinusMovingAverage1 = sm.add_constant(logScaleMinusMovingAverage1)\n",
    "    results = sm.OLS(logScaleMinusMovingAverage2,logScaleMinusMovingAverage1['close']).fit()\n",
    "    b = results.params['close']\n",
    "    z = logScaleMinusMovingAverage1['close'] - (b * logScaleMinusMovingAverage2)\n",
    "    coint = test_CointegrationOfCombinedSeriesKMean(z)\n",
    "    return coint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster number: 0\n",
      "Old length of cluster : 16\n",
      "New length of cluster : 14\n",
      "Total pairs:  91\n",
      "Number of True: 24\n",
      "Number of False: 67\n",
      "---------------------------------------------------------------\n",
      "Cluster number: 1\n",
      "Old length of cluster : 7\n",
      "New length of cluster : 6\n",
      "Total pairs:  15\n",
      "Number of True: 1\n",
      "Number of False: 14\n",
      "---------------------------------------------------------------\n",
      "Cluster number: 2\n",
      "Old length of cluster : 480\n",
      "New length of cluster : 439\n",
      "Total pairs:  96141\n",
      "Number of True: 20274\n",
      "Number of False: 75867\n",
      "---------------------------------------------------------------\n",
      "Cluster number: 3\n",
      "Old length of cluster : 1\n",
      "New length of cluster : 1\n",
      "Total pairs:  0\n",
      "Number of True: 0\n",
      "Number of False: 0\n",
      "---------------------------------------------------------------\n",
      "Cluster number: 4\n",
      "Old length of cluster : 1\n",
      "New length of cluster : 1\n",
      "Total pairs:  0\n",
      "Number of True: 0\n",
      "Number of False: 0\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def coIntTestForCluster(dfCluster,ClusterNumber):\n",
    "    print('Cluster number: '+ str(ClusterNumber))\n",
    "    ListOfCompInOneCluster = dfCluster['Name'].tolist()\n",
    "    print('Old length of cluster : '+ str(len(ListOfCompInOneCluster)))\n",
    "    for i in range(0,len(badCompanies)):\n",
    "        if badCompanies[i] in ListOfCompInOneCluster :\n",
    "            #print(\"Bad Company found in Cluster: \" , badCompanies[i])\n",
    "            ListOfCompInOneCluster.remove(badCompanies[i])\n",
    "    print('New length of cluster : '+ str(len(ListOfCompInOneCluster)))\n",
    "\n",
    "    ListOfPairs = list(itertools.combinations(ListOfCompInOneCluster, 2))\n",
    "    #print(ListOfPairs[:2])\n",
    "    #print(len(ListOfPairs))\n",
    "    #print(ListOfPairs[0][0],ListOfPairs[0][1])\n",
    "\n",
    "    pair_result_dict = {}\n",
    "    for x in range(0,len(ListOfPairs)):\n",
    "        pair_result_dict[ListOfPairs[x]] = []\n",
    "\n",
    "    for i in range(0,len(ListOfPairs)):\n",
    "        dfX = df1.loc[df1['Name']==ListOfPairs[i][0]]\n",
    "        dfY = df1.loc[df1['Name']==ListOfPairs[i][1]]\n",
    "        Result = ImproveStationarity_and_test_CointegrationKMean(dfX,dfY)\n",
    "        pair_result_dict[ListOfPairs[i]] = Result\n",
    "\n",
    "    ListOfValuesCluster_2=list(pair_result_dict.values())\n",
    "    print('Total pairs:  ' + str(len(ListOfValuesCluster_2)))\n",
    "    print('Number of True: ' + str(ListOfValuesCluster_2.count(True)))\n",
    "    print('Number of False: ' + str(ListOfValuesCluster_2.count(False)))\n",
    "    print('---------------------------------------------------------------')\n",
    "    return pair_result_dict\n",
    "\n",
    "listOfClusters = [dfCluster1m,dfCluster2m,dfCluster3m,dfCluster4m,dfCluster5m]\n",
    "listOfResultDict = []\n",
    "\n",
    "for c in range(0,len(listOfClusters)):\n",
    "    res = coIntTestForCluster(listOfClusters[c],c)\n",
    "    listOfResultDict.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "ListOfCointPairs = []\n",
    "for key, value in listOfResultDict[0].items():\n",
    "    if value == True:\n",
    "        ListOfCointPairs.append(key)\n",
    "dfCoInt = pd.DataFrame({'Pairs':ListOfCointPairs})\n",
    "dfCoInt.head(5)\n",
    "dfCoInt.to_csv('C:/Users/archana.parihar/Downloads/ResultsSnP/ListOfPairs_5_K_Means_cluster_1_Pvalue_02.csv',index=False, sep=',',encoding='utf-8')\n",
    "\n",
    "print(len(ListOfCointPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "ListOfCointPairs = []\n",
    "for key, value in listOfResultDict[1].items():\n",
    "    if value == True:\n",
    "        ListOfCointPairs.append(key)\n",
    "dfCoInt = pd.DataFrame({'Pairs':ListOfCointPairs})\n",
    "dfCoInt.head(5)\n",
    "dfCoInt.to_csv('C:/Users/archana.parihar/Downloads/ResultsSnP/ListOfPairs_5_K_Means_cluster_2_Pvalue_02.csv',index=False, sep=',',encoding='utf-8')\n",
    "print(len(ListOfCointPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20274\n"
     ]
    }
   ],
   "source": [
    "ListOfCointPairs = []\n",
    "for key, value in listOfResultDict[2].items():\n",
    "    if value == True:\n",
    "        ListOfCointPairs.append(key)\n",
    "dfCoInt = pd.DataFrame({'Pairs':ListOfCointPairs})\n",
    "dfCoInt.head(5)\n",
    "dfCoInt.to_csv('C:/Users/archana.parihar/Downloads/ResultsSnP/ListOfPairs_5_K_Means_cluster_3_Pvalue_02.csv',index=False, sep=',',encoding='utf-8')\n",
    "print(len(ListOfCointPairs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
